{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPJenlrhihrh"
   },
   "source": [
    "# MNIST 실습\n",
    "\n",
    "이번에는 28x28 흑백 손글씨 이미지를 보고 0~9 사이의 숫자 중 어떤 숫자를 쓴 것인지 예측하는 문제를 실습합니다.\n",
    "이번 실습에서는 GPU를 활용할 것이기 때문에, 이전 챕터에서 Colab에서 GPU를 설정하는 방법을 따라해주시길 바랍니다.\n",
    "\n",
    "GPU를 설정했으면 library들을 import합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6315,
     "status": "ok",
     "timestamp": 1724212693193,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "6lXVfXoDtoQh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
    "\n",
    "\n",
    "import torch\n",
    "# GPU 사용 가능하면 cuda, 아니면 cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pF-1zQvmiult"
   },
   "source": [
    "다음은 dataset을 준비합니다. 손글씨 dataset은 MNIST라는 유명한 dataset이 있습니다. 이 dataset은 `torchvision`에서 제공하고 있으며, 다음과 같이 다운로드 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22007,
     "status": "ok",
     "timestamp": 1724212718261,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "KAYlqPaRt6ti",
    "outputId": "67e51d96-85b4-4129-efc8-7938006afdd4"
   },
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-GqH7_ZjVMs"
   },
   "source": [
    "MNIST는 손글씨 사진과 어떤 숫자를 의미하는지에 대한 label의 pair들로 구성되어있습니다.\n",
    "이 때, 우리는 PyTorch model을 사용할 것이기 때문에 손글씨 사진들을 모두 tensor로 변환해야합니다.\n",
    "이러한 부가적인 변환들은 `torchvision.transforms`에서 제공하고 있으며, `torchvision.datasets.MNIST`에서 `transform` 인자로 받을 수 있습니다.\n",
    "우리는 단순히 사진을 tensor로 바꾸고 싶기 때문에 `transforms.ToTensor()` transformation을 넘겨줍니다.\n",
    "\n",
    "다음은 전체 data의 개수와 첫 번째 data를 출력한 결과입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1724212727291,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "Zsp3sHmojyhT",
    "outputId": "3511bb75-e677-4fb8-894b-69e22c80f4bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "torch.Size([1, 28, 28]) 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3118da610>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "print(len(trainset))\n",
    "print(trainset[0][0].shape, trainset[0][1])\n",
    "plt.imshow(trainset[0][0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udm8wDBsi301"
   },
   "source": [
    "첫 번째 출력결과를 통해 우리는 6만장의 손글씨 data가 있는 것을 알 수 있습니다.\n",
    "그리고 두 번째 출력결과를 통해 첫 번째 data의 shape은 (1, 28, 28)이고 5라는 숫자를 쓴 사진이라는 것을 알 수 있습니다.\n",
    "마지막으로 `plt.imshow`를 통해 visualize 했을 때 5라는 숫자가 나오는 것을 알 수 있습니다.\n",
    "\n",
    "다음은 SGD를 위해 dataset을 여러 개의 batch로 나누는 과정을 PyTorch로 구현한 모습입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UxKu3kA2i5WH"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4Qyrm4WlzWt"
   },
   "source": [
    "PyTorch에서는 `DataLoader`가 dataset을 인자로 받아 batch로 나눠줍니다.\n",
    "부가적으로 `batch_size`라는 인자를 통해 batch size를 받고 있으며, `shuffle`이라는 인자를 통해 data들을 섞을지 결정해줍니다.\n",
    "우리는 SGD가 완전 랜덤으로 batch를 구성해야 잘 동작하는 것을 알고 있기 때문에 `shuffle`에 `True`를 넘겨주고 있습니다.\n",
    "\n",
    "다음은 첫 번째 batch를 출력한 모습입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1723366306519,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "_Hd7XxyAvVNz",
    "outputId": "185acb61-2ed7-4110-b325-c0e016ca60b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0ZY5mDimRUK"
   },
   "source": [
    "`images`는 첫 번째 batch의 image들이고 `labels`는 첫 번째 batch의 label들입니다.\n",
    "위에서 batch size를 64로 설정했기 때문에 총 64개의 image와 label들이 있어야 합니다.\n",
    "실제 shape 출력 결과를 보면 그렇다는 것을 알 수 있습니다.\n",
    "\n",
    "다음은 (n, 1, 28, 28) shape의 image를 입력받아 0~9 사이의 정수 하나를 출력하는 3-layer MLP를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OLOA-ZGTuVVG"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "  def __init__(self, input_dim, n_dim):\n",
    "    super().__init__()\n",
    "\n",
    "    self.layer1 = nn.Linear(input_dim, n_dim)\n",
    "    self.layer2 = nn.Linear(n_dim, n_dim)\n",
    "    self.layer3 = nn.Linear(n_dim, 1)\n",
    "\n",
    "    self.act = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.flatten(x, start_dim=1)\n",
    "    x = self.act(self.layer1(x))\n",
    "    x = self.act(self.layer2(x))\n",
    "    x = self.act(self.layer3(x))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "model = Model(28 * 28 * 1, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tag1rNcwmnAr"
   },
   "source": [
    "이전의 2-layer MLP와 유사한 형태임을 알 수 있습니다.\n",
    "여기서 특이사항은 `forward`의 첫 번째 줄에 `torch.flatten`을 사용한다는 것입니다.\n",
    "`Linear`는 이전에도 봤다시피 (n, d) 형태의 shape을 입력받습니다.\n",
    "이미지는 (n, 1, 28, 28)이기 때문에 (n, 1 * 28 * 28)로 shape을 변환해야 선형 함수에 입력으로 주어줄 수 있게 됩니다.\n",
    "이 역할을 수행하는 것이 바로 `torch.flatten`입니다.\n",
    "우리는 첫 번째 shape인 n을 보존할 것이기 때문에 flatten할 차원은 `start_dim=1`로 넘겨주게 됩니다.\n",
    "\n",
    "다음은 gradient descent를 수행해줄 optimizer를 구현하는 모습입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "\n",
    "model 의 레이어 설정과 파라미터들을 최적화 함수에 전달해주고 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ypS0TcOlvBhZ"
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "lr = 0.001\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PooeOKMnRfZ"
   },
   "source": [
    "이전 코드와 거의 똑같습니다. 다른 점은 `model.to('cuda')` 코드를 통해 우리가 구현한 model을 GPU로 옮긴 것입니다.\n",
    "MNIST 부터는 모델과 data가 커지면서 훨씬 많은 행렬 연산이 이루어지기 때문에 GPU를 활용하는 것이 빠릅니다.\n",
    "\n",
    "다음은 model을 MNIST에 학습하는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# n_epochs = 100\n",
    "\n",
    "# for epoch in range(n_epochs):\n",
    "#   total_loss = 0.\n",
    "#   for data in trainloader:\n",
    "#     model.zero_grad()\n",
    "#     inputs, labels = data\n",
    "#     inputs, labels = inputs, labels\n",
    "\n",
    "#     preds = model(inputs)\n",
    "#     loss = (preds[:, 0] - labels).pow(2).mean()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     total_loss += loss.item()\n",
    "#   print(f\"Epoch {epoch:3d} | Loss: {total_loss}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 786155,
     "status": "ok",
     "timestamp": 1723367093025,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "TryX1hewvNiB",
    "outputId": "4e4a9282-d49a-40ff-c26c-d00fb7c0af79"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb4aef1cb604fc784f6446c5217f174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Loss: 4653.015336\n",
      "Epoch   1 | Loss: 2588.564032\n",
      "Epoch   2 | Loss: 1884.207978\n",
      "Epoch   3 | Loss: 1473.905066\n",
      "Epoch   4 | Loss: 1231.390529\n",
      "Epoch   5 | Loss: 1075.365229\n",
      "Epoch   6 | Loss: 970.751560\n",
      "Epoch   7 | Loss: 894.046826\n",
      "Epoch   8 | Loss: 830.824579\n",
      "Epoch   9 | Loss: 780.019801\n",
      "Epoch  10 | Loss: 736.316732\n",
      "Epoch  11 | Loss: 697.993762\n",
      "Epoch  12 | Loss: 667.390667\n",
      "Epoch  13 | Loss: 635.335004\n",
      "Epoch  14 | Loss: 609.876655\n",
      "Epoch  15 | Loss: 585.013957\n",
      "Epoch  16 | Loss: 561.926677\n",
      "Epoch  17 | Loss: 542.548904\n",
      "Epoch  18 | Loss: 525.594771\n",
      "Epoch  19 | Loss: 507.672356\n",
      "Epoch  20 | Loss: 493.171883\n",
      "Epoch  21 | Loss: 475.004603\n",
      "Epoch  22 | Loss: 458.071189\n",
      "Epoch  23 | Loss: 447.589626\n",
      "Epoch  24 | Loss: 433.588935\n",
      "Epoch  25 | Loss: 419.726309\n",
      "Epoch  26 | Loss: 409.580270\n",
      "Epoch  27 | Loss: 399.354199\n",
      "Epoch  28 | Loss: 385.240043\n",
      "Epoch  29 | Loss: 375.258968\n",
      "Epoch  30 | Loss: 367.686214\n",
      "Epoch  31 | Loss: 359.669876\n",
      "Epoch  32 | Loss: 349.386077\n",
      "Epoch  33 | Loss: 341.795725\n",
      "Epoch  34 | Loss: 330.004994\n",
      "Epoch  35 | Loss: 320.860782\n",
      "Epoch  36 | Loss: 316.460260\n",
      "Epoch  37 | Loss: 309.723775\n",
      "Epoch  38 | Loss: 304.768250\n",
      "Epoch  39 | Loss: 294.977573\n",
      "Epoch  40 | Loss: 288.499712\n",
      "Epoch  41 | Loss: 287.363305\n",
      "Epoch  42 | Loss: 277.565365\n",
      "Epoch  43 | Loss: 276.255618\n",
      "Epoch  44 | Loss: 265.755810\n",
      "Epoch  45 | Loss: 262.390995\n",
      "Epoch  46 | Loss: 258.219479\n",
      "Epoch  47 | Loss: 249.615316\n",
      "Epoch  48 | Loss: 243.180208\n",
      "Epoch  49 | Loss: 240.976251\n",
      "Epoch  50 | Loss: 232.028577\n",
      "Epoch  51 | Loss: 235.054122\n",
      "Epoch  52 | Loss: 229.114202\n",
      "Epoch  53 | Loss: 222.519970\n",
      "Epoch  54 | Loss: 219.688638\n",
      "Epoch  55 | Loss: 218.680124\n",
      "Epoch  56 | Loss: 209.463974\n",
      "Epoch  57 | Loss: 203.662627\n",
      "Epoch  58 | Loss: 203.001416\n",
      "Epoch  59 | Loss: 195.557756\n",
      "Epoch  60 | Loss: 198.650919\n",
      "Epoch  61 | Loss: 191.202993\n",
      "Epoch  62 | Loss: 190.457563\n",
      "Epoch  63 | Loss: 185.213824\n",
      "Epoch  64 | Loss: 182.140782\n",
      "Epoch  65 | Loss: 183.460885\n",
      "Epoch  66 | Loss: 178.838023\n",
      "Epoch  67 | Loss: 170.368895\n",
      "Epoch  68 | Loss: 166.952619\n",
      "Epoch  69 | Loss: 170.704227\n",
      "Epoch  70 | Loss: 171.276140\n",
      "Epoch  71 | Loss: 163.170341\n",
      "Epoch  72 | Loss: 161.477503\n",
      "Epoch  73 | Loss: 158.809344\n",
      "Epoch  74 | Loss: 152.720185\n",
      "Epoch  75 | Loss: 146.032269\n",
      "Epoch  76 | Loss: 150.492489\n",
      "Epoch  77 | Loss: 147.831691\n",
      "Epoch  78 | Loss: 143.208404\n",
      "Epoch  79 | Loss: 143.140898\n",
      "Epoch  80 | Loss: 144.846156\n",
      "Epoch  81 | Loss: 139.233098\n",
      "Epoch  82 | Loss: 127.278405\n",
      "Epoch  83 | Loss: 133.565761\n",
      "Epoch  84 | Loss: 135.212805\n",
      "Epoch  85 | Loss: 127.205109\n",
      "Epoch  86 | Loss: 129.040911\n",
      "Epoch  87 | Loss: 129.939530\n",
      "Epoch  88 | Loss: 125.125114\n",
      "Epoch  89 | Loss: 126.889340\n",
      "Epoch  90 | Loss: 122.666635\n",
      "Epoch  91 | Loss: 115.767343\n",
      "Epoch  92 | Loss: 118.804721\n",
      "Epoch  93 | Loss: 120.007109\n",
      "Epoch  94 | Loss: 118.882089\n",
      "Epoch  95 | Loss: 115.014710\n",
      "Epoch  96 | Loss: 116.815895\n",
      "Epoch  97 | Loss: 111.937419\n",
      "Epoch  98 | Loss: 112.509597\n",
      "Epoch  99 | Loss: 109.014624\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "# tqdm으로 에폭 진행상황 표시\n",
    "for epoch in tqdm(range(n_epochs), desc=\"Training\"):\n",
    "    total_loss = 0.\n",
    "    for data in trainloader:\n",
    "        model.zero_grad()\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # 중복 할당 수정\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # device 설정 추가\n",
    "\n",
    "        preds = model(inputs)\n",
    "        loss = (preds[:, 0] - labels).pow(2).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # 각 에폭이 끝날 때 tqdm.write로 손실 출력\n",
    "    tqdm.write(f\"Epoch {epoch:3d} | Loss: {total_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRDcptrqniX7"
   },
   "source": [
    "출력 결과를 보면 잘 수렴하는 것을 볼 수 있습니다.\n",
    "이전 구현과 다른 점은 다음 두 가지입니다.\n",
    "- `for data in trainloader`를 통해 batch들을 iterate하면서 model을 학습합니다.\n",
    "- `inputs, labels = inputs.to('cuda'), labels.to('cuda')`를 통해 model의 입력으로 들어가는 tensor들을 GPU로 보냅니다.\n",
    "\n",
    "마지막으로 첫 번째 data에 대한 예측 결과를 살펴봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "\n",
    "None을 붙이는 것에는 model이 텐서를 받을 때 배치 된 텐서를 받는 것을 기대하고 있어서임\n",
    "trainset[idx][0].unsqueeze(0) 과 기능이 같다고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1723367093026,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "Zct0ssSKwjt1",
    "outputId": "4a8d7062-1a43-4522-895e-cfebb9c02cdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 1, 28, 28])\n",
      "tensor([[4.7921]], grad_fn=<ReluBackward0>)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "x = trainset[idx][0]  # (1, 1, 28, 28)\n",
    "print(x.shape)\n",
    "x = x[None]\n",
    "print(x.shape)\n",
    "\n",
    "print(model(x))\n",
    "print(trainset[idx][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzgSOrMsoZ2z"
   },
   "source": [
    "여기서 idx를 조정하여 다른 data에 대한 출력 결과도 볼 수 있습니다.\n",
    "예측 결과를 보시면 아직 성능이 그렇게 좋지 않은 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6M4SpWQoML9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOz7vBAsZ4WYLph4xp9q2ee",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
