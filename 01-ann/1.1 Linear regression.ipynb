{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dS_t0-ik_WC1"
   },
   "source": [
    "# Linear Regression 실습\n",
    "\n",
    "이번 실습에서는 linear regression에 대한 gradient descent를 직접 구현해봅니다. 여기서 사용할 문제들은 크게 두 가지로 OR 문제와 XOR 문제입니다.\n",
    "\n",
    "먼저 필요한 library들을 import합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1723361278387,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "DEJFJkL6qHB9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import List, Tuple, Dict, Any, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "\n",
    "텐서로 정의되는 2차원이 4개 들어가있는 x 한개를 (4,2) 라고 부른다?\n",
    "아님 2차원 데이터 4개?를 표현한 것?\n",
    "\n",
    "### randn 의 정의\n",
    "\n",
    "randn 은 표준 정규 분포에서 랜덤 샘플을 추출하는 함수이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1차원 텐서 생성 (길이 4)\n",
    "x = torch.randn(4)\n",
    "# 결과 예시: tensor([-2.1436, 0.9966, 2.3426, -0.6366])\n",
    "\n",
    "# 2차원 텐서 생성 (2행 3열)\n",
    "y = torch.randn(2, 3)\n",
    "# 결과 예시: tensor([[ 1.5954, 2.8929, -1.0923],\n",
    "#                   [ 1.1719, -0.4709, -0.1996]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cG2fJsOF8LsP"
   },
   "source": [
    "## OR Problem\n",
    "\n",
    "OR은 0 또는 1의 값을 가질 수 있는 두 개의 정수를 입력으로 받아 둘 중에 하나라도 1이면 1을 출력하고 아니면 0을 출력하는 문제입니다.\n",
    "즉, 우리가 학습하고자 하는 함수는 2개의 정수를 입력받아 하나의 정수를 출력하면됩니다. 이러한 함수를 학습하기 위한 data는 다음과 같이 구성할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "\n",
    "텐서를 정의하는 개념에 대해 설명한다\n",
    "우선 하나의 텐서에 대한 정의로 n차원이든 정의된다\n",
    "\n",
    "그리고 그 크기에 대해 사이즈를 아래 예시의 2차원 백터 4 개는 shape를 봤을 떄 [4,2] 처럼 정의된다\n",
    "여기서 나의 해석 방법과 텐서의 해석 방법이 다른데\n",
    "텐서는 데이터의 개수를 먼저 정의하고 그 뒤에 데이터의 차원을 세고 있는 것을 알 수 있다\n",
    "\n",
    "```\n",
    "x = torch.tensor([\n",
    "    [0., 0.],\n",
    "    [0., 1.],\n",
    "    [1., 0.],\n",
    "    [1., 1.]\n",
    "]) \n",
    "```\n",
    "에 대해 해석할 때\n",
    "\n",
    "해석하면 다음과 같다 일단 텐서에는 4개의 A 텐서가 있다 > A는 벡터를 담고 있는 텐서이다?\n",
    "이러한 텐서의 정의를 통해 우리는 데이터의 개수와 데이터의 차원을 명확하게 알 수 있고 이를 통해 우리는 데이터의 형태를 파악할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 x와 y는 입력 데이터와 출력 데이터다\n",
    "\n",
    "or이기 때문에 정답이 0,1,1,1 인 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1723361278864,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "SsEdD6T7qLJH",
    "outputId": "a8c91b61-98b4-45af-be7b-865abe2c8b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [0., 0.],\n",
    "    [0., 1.],\n",
    "    [1., 0.],\n",
    "    [1., 1.]\n",
    "])\n",
    "y = torch.tensor([0, 1, 1, 1])\n",
    "\n",
    "print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyD1n6wf_3ey"
   },
   "source": [
    "출력 결과에서 볼 수 있다시피 $x$의 shape은 (4, 2)로, 총 4개의 two-dimensional data 임을 알 수 있습니다. $y$는 각 $x_i$에 대한 label로 우리가 설정한 문제의 조건을 잘 따라가는 것을 알 수 있습니다.\n",
    "\n",
    "다음으로는 linear regression의 parameter들인 $w, b$를 정의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1723361279282,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "uzG4w1VYqlhz",
    "outputId": "8c5ad5c5-dea3-4b59-cebe-feeca50507f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2]) torch.Size([1, 1])\n",
      "tensor([[ 1.3616, -0.1143]]) tensor([[0.4757]])\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn((1, 2))\n",
    "b = torch.randn((1, 1))\n",
    "\n",
    "print(w.shape, b.shape)\n",
    "print(w, b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELTb9Dl-AYbp"
   },
   "source": [
    "$w$는 1x2의 벡터이고 $b$는 1x1의 scalar임을 알 수 있습니다. 여기서는 `torch.randn`을 사용하여 standard normal distribution을 가지고 초기화하였습니다.\n",
    "\n",
    "이러한 $w, b$와 data $x, y$가 주어졌을 때 우리가 학습한 $w, b$의 성능을 평가하는 함수를 구현합시다.\n",
    "평가 함수는 다음과 같이 MSE로 정의됩니다:\n",
    "$$l(f) := MSE(f(x), y) = \\frac{1}{n} \\sum_{i=1}^n (f(x_i) - y)^2.$$\n",
    "이를 구현한 코드는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "\n",
    "여기서 w는 전체 영역의 크기에 대해 정의하고 있고\n",
    "b는 한개의 스칼라를 정의하고 있음을 알 수 있다\n",
    "\n",
    "pred 는 결과 출력할 때 사용한 함수임\n",
    "\n",
    "w는 전체 영역의 현재 가중치\n",
    "x.T 는 행렬 계산을 위해 순서를 맞추기 위한 전치\n",
    "\n",
    "b는 현재 입력 값에 대해 추가할 편향 값\n",
    "\n",
    "\n",
    "x.T는 한 번에 모든 데이터 샘플에 대한 계산을 수행하기 위해 행렬의 축을 재정렬하는 것\n",
    "\n",
    "크기는 작지만 x는 데이터 입력 라고 할 수 있음\n",
    "\n",
    "이것이 바로 효율적인 벡터화 연산의 핵심으로, 딥러닝에서 배치 처리를 할 때 굉장히 중요한 기법 \n",
    "한 번의 연산으로 모든 샘플에 대한 계산을 수행하므로 개별적으로 처리하는 것보다 훨씬 빠르다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1723361279282,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "LBxldV7D8UMf"
   },
   "outputs": [],
   "source": [
    "def pred(w, b, x):\n",
    "  print('pred:',w, b, x ,x.T)\n",
    "  return torch.matmul(w, x.T) + b\n",
    "\n",
    "\n",
    "def loss(w, b, x, y):\n",
    "  return (y - pred(w, b, x)).pow(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmM79Ly6VyBw",
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "먼저 `def pred(w, b, x)`는 $wx^T + b$, 즉 1차 함수 $f$의 $x$에 대한 결과를 반환하는 함수를 구현했습니다.\n",
    "이를 이용하여 주어진 label $y$와의 MSE를 측정하는 코드가 `def loss(w, b, x, y)`에 구현되어있습니다.\n",
    "\n",
    "다음은 MSE를 기반으로 $w, b$의 gradient를 구하는 코드를 구현하겠습니다.\n",
    "MSE에 대한 $w$의 gradient는 다음과 같이 구할 수 있습니다:\n",
    "$$\\frac{\\partial l}{\\partial w} = \\frac{1}{n} \\sum_{i=1}^n 2(wx_i^T + b - y)x_i.$$\n",
    "$b$에 대한 gradient는 다음과 같습니다:\n",
    "$$\\frac{\\partial l}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^n 2(wx_i^T + b - y).$$\n",
    "이를 코드로 구현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1723361279282,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "rLrsXZ0iq13m"
   },
   "outputs": [],
   "source": [
    "def grad_w(w, b, x, y):\n",
    "  # w: (1, d), b: (1, 1), x: (n, d), y: (n)\n",
    "  tmp1 = torch.matmul(w, x.T)  # (1, n)\n",
    "  tmp2 = tmp1 + b              # (1, n)\n",
    "  tmp3 = 2 * (tmp2 - y[None])  # (1, n)\n",
    "  grad_item = tmp3.T * x       # (n, d)\n",
    "  return grad_item.mean(dim=0, keepdim=True)  # (1, d)\n",
    "\n",
    "\n",
    "def grad_b(w, b, x, y):\n",
    "  # w: (1, d), b: (1, 1), x: (n, d), y: (n)\n",
    "  grad_item = 2 * (torch.matmul(w, x.T) + b - y[None])  # (1, n)\n",
    "  return grad_item.mean(dim=-1, keepdim=True)           # (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCbBU1RaX6O5"
   },
   "source": [
    "여기서 중요한 것은 shape에 맞춰서 연산을 잘 사용해야한다는 것입니다. Shape과 관련된 설명은 `[Chapter 0]`의 Numpy에서 설명했으니, 복습하신다는 느낌으로 주석으로 써놓은 shape들을 유도해보시면 좋을 것 같습니다. 중요한 것은 반환되는 tensor의 shape이 우리가 구하고자 하는 gradient와 일치해야 한다는 것입니다. 예를 들어 $w$의 $l$에 대한 gradient는 $w$와 shape이 동일해야 합니다.\n",
    "\n",
    "마지막으로 gradient descent 함수를 구현하겠습니다. Gradient descent는 다음과 같이 정의됩니다:\n",
    "$$w^{(new)} = w^{(old)} - \\eta \\frac{\\partial l}{\\partial w} \\biggr\\rvert_{w = w^{(old)}}.$$\n",
    "Gradient는 위에서 구현했으니 이를 활용하여 learning rate $\\eta$가 주어졌을 때 $w, b$를 update하는 코드를 구현할 수 있습니다. 구현한 결과는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1723361279282,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "wFRS72UF8QVv"
   },
   "outputs": [],
   "source": [
    "def update(x, y, w, b, lr):\n",
    "  w = w - lr * grad_w(w, b, x, y)\n",
    "  b = b - lr * grad_b(w, b, x, y)\n",
    "  return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b93uvneVZ7bF"
   },
   "source": [
    "Gradient descent(경사 하강법)에 해당하는 코드는 모두 구현하였습니다. 이제 학습하는 코드를 구현하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1723361279283,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "Pa6fA_ZUFI-0"
   },
   "outputs": [],
   "source": [
    "def train(n_epochs, lr, w, b, x, y):\n",
    "  for e in range(n_epochs):\n",
    "    w, b = update(x, y, w, b, lr)\n",
    "    print(f\"Epoch {e:3d} | Loss: {loss(w, b, x, y)}\")\n",
    "  return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrJGKWilaBFq"
   },
   "source": [
    "여기서 `n_epochs`는 update를 하는 횟수를 의미합니다. 매 update 이후에 `loss` 함수를 사용하여 잘 수렴하고 있는지 살펴봅니다. 실제로 이 함수를 실행한 결과는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1723361279283,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "zFk-josgBSj7",
    "outputId": "ec127ca9-a563-43ac-8adc-8e1e398ecb5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[ 1.2836, -0.1185]]) tensor([[0.4140]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   0 | Loss: 0.3724440932273865\n",
      "pred: tensor([[ 1.2198, -0.1122]]) tensor([[0.3705]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   1 | Loss: 0.31607845425605774\n",
      "pred: tensor([[ 1.1664, -0.0990]]) tensor([[0.3396]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   2 | Loss: 0.27842044830322266\n",
      "pred: tensor([[ 1.1207, -0.0814]]) tensor([[0.3178]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   3 | Loss: 0.25097325444221497\n",
      "pred: tensor([[ 1.0809, -0.0611]]) tensor([[0.3022]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   4 | Loss: 0.22943778336048126\n",
      "pred: tensor([[ 1.0457, -0.0392]]) tensor([[0.2911]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   5 | Loss: 0.2116023749113083\n",
      "pred: tensor([[ 1.0140, -0.0167]]) tensor([[0.2832]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   6 | Loss: 0.19629716873168945\n",
      "pred: tensor([[0.9851, 0.0059]]) tensor([[0.2774]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   7 | Loss: 0.18287503719329834\n",
      "pred: tensor([[0.9585, 0.0284]]) tensor([[0.2733]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   8 | Loss: 0.17095443606376648\n",
      "pred: tensor([[0.9339, 0.0503]]) tensor([[0.2702]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   9 | Loss: 0.16029104590415955\n",
      "pred: tensor([[0.9110, 0.0715]]) tensor([[0.2679]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  10 | Loss: 0.15071405470371246\n",
      "pred: tensor([[0.8895, 0.0920]]) tensor([[0.2662]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  11 | Loss: 0.14209367334842682\n",
      "pred: tensor([[0.8694, 0.1117]]) tensor([[0.2648]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  12 | Loss: 0.13432490825653076\n",
      "pred: tensor([[0.8504, 0.1306]]) tensor([[0.2638]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  13 | Loss: 0.12731891870498657\n",
      "pred: tensor([[0.8324, 0.1487]]) tensor([[0.2629]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  14 | Loss: 0.12099854648113251\n",
      "pred: tensor([[0.8155, 0.1659]]) tensor([[0.2622]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  15 | Loss: 0.11529558151960373\n",
      "pred: tensor([[0.7994, 0.1823]]) tensor([[0.2616]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  16 | Loss: 0.11014911532402039\n",
      "pred: tensor([[0.7842, 0.1979]]) tensor([[0.2611]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  17 | Loss: 0.1055046021938324\n",
      "pred: tensor([[0.7698, 0.2128]]) tensor([[0.2606]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  18 | Loss: 0.10131298005580902\n",
      "pred: tensor([[0.7561, 0.2270]]) tensor([[0.2602]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  19 | Loss: 0.09752998501062393\n",
      "pred: tensor([[0.7431, 0.2405]]) tensor([[0.2598]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  20 | Loss: 0.09411579370498657\n",
      "pred: tensor([[0.7308, 0.2533]]) tensor([[0.2594]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  21 | Loss: 0.09103438258171082\n",
      "pred: tensor([[0.7191, 0.2655]]) tensor([[0.2591]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  22 | Loss: 0.08825334906578064\n",
      "pred: tensor([[0.7080, 0.2771]]) tensor([[0.2587]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  23 | Loss: 0.08574336767196655\n",
      "pred: tensor([[0.6975, 0.2881]]) tensor([[0.2584]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  24 | Loss: 0.08347807824611664\n",
      "pred: tensor([[0.6875, 0.2986]]) tensor([[0.2581]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  25 | Loss: 0.08143357932567596\n",
      "pred: tensor([[0.6780, 0.3085]]) tensor([[0.2579]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  26 | Loss: 0.07958835363388062\n",
      "pred: tensor([[0.6690, 0.3180]]) tensor([[0.2576]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  27 | Loss: 0.07792298495769501\n",
      "pred: tensor([[0.6604, 0.3270]]) tensor([[0.2573]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  28 | Loss: 0.07641995698213577\n",
      "pred: tensor([[0.6523, 0.3355]]) tensor([[0.2571]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  29 | Loss: 0.07506340742111206\n",
      "pred: tensor([[0.6446, 0.3436]]) tensor([[0.2568]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  30 | Loss: 0.07383907586336136\n",
      "pred: tensor([[0.6373, 0.3514]]) tensor([[0.2566]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  31 | Loss: 0.07273408770561218\n",
      "pred: tensor([[0.6303, 0.3587]]) tensor([[0.2564]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  32 | Loss: 0.07173679769039154\n",
      "pred: tensor([[0.6237, 0.3657]]) tensor([[0.2562]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  33 | Loss: 0.07083669304847717\n",
      "pred: tensor([[0.6174, 0.3723]]) tensor([[0.2560]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  34 | Loss: 0.07002434134483337\n",
      "pred: tensor([[0.6115, 0.3786]]) tensor([[0.2558]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  35 | Loss: 0.06929115206003189\n",
      "pred: tensor([[0.6058, 0.3846]]) tensor([[0.2556]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  36 | Loss: 0.06862941384315491\n",
      "pred: tensor([[0.6005, 0.3903]]) tensor([[0.2554]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  37 | Loss: 0.0680321604013443\n",
      "pred: tensor([[0.5954, 0.3957]]) tensor([[0.2552]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  38 | Loss: 0.06749314069747925\n",
      "pred: tensor([[0.5905, 0.4008]]) tensor([[0.2550]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  39 | Loss: 0.06700663268566132\n",
      "pred: tensor([[0.5859, 0.4057]]) tensor([[0.2549]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  40 | Loss: 0.06656754016876221\n",
      "pred: tensor([[0.5816, 0.4104]]) tensor([[0.2547]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  41 | Loss: 0.06617125868797302\n",
      "pred: tensor([[0.5774, 0.4148]]) tensor([[0.2545]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  42 | Loss: 0.0658135637640953\n",
      "pred: tensor([[0.5735, 0.4190]]) tensor([[0.2544]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  43 | Loss: 0.0654907375574112\n",
      "pred: tensor([[0.5697, 0.4230]]) tensor([[0.2542]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  44 | Loss: 0.0651993677020073\n",
      "pred: tensor([[0.5662, 0.4268]]) tensor([[0.2541]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  45 | Loss: 0.06493639945983887\n",
      "pred: tensor([[0.5628, 0.4304]]) tensor([[0.2539]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  46 | Loss: 0.06469905376434326\n",
      "pred: tensor([[0.5596, 0.4338]]) tensor([[0.2538]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  47 | Loss: 0.06448481976985931\n",
      "pred: tensor([[0.5566, 0.4371]]) tensor([[0.2537]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  48 | Loss: 0.06429149210453033\n",
      "pred: tensor([[0.5537, 0.4402]]) tensor([[0.2536]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  49 | Loss: 0.06411698460578918\n",
      "pred: tensor([[0.5510, 0.4431]]) tensor([[0.2534]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  50 | Loss: 0.06395947188138962\n",
      "pred: tensor([[0.5484, 0.4459]]) tensor([[0.2533]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  51 | Loss: 0.0638173297047615\n",
      "pred: tensor([[0.5459, 0.4486]]) tensor([[0.2532]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  52 | Loss: 0.06368901580572128\n",
      "pred: tensor([[0.5436, 0.4511]]) tensor([[0.2531]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  53 | Loss: 0.06357321888208389\n",
      "pred: tensor([[0.5414, 0.4535]]) tensor([[0.2530]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  54 | Loss: 0.06346868723630905\n",
      "pred: tensor([[0.5392, 0.4558]]) tensor([[0.2529]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  55 | Loss: 0.06337437033653259\n",
      "pred: tensor([[0.5372, 0.4579]]) tensor([[0.2528]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  56 | Loss: 0.06328921020030975\n",
      "pred: tensor([[0.5353, 0.4600]]) tensor([[0.2527]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  57 | Loss: 0.06321234256029129\n",
      "pred: tensor([[0.5335, 0.4620]]) tensor([[0.2526]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  58 | Loss: 0.06314299255609512\n",
      "pred: tensor([[0.5318, 0.4638]]) tensor([[0.2525]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  59 | Loss: 0.06308038532733917\n",
      "pred: tensor([[0.5302, 0.4656]]) tensor([[0.2524]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  60 | Loss: 0.0630238726735115\n",
      "pred: tensor([[0.5287, 0.4673]]) tensor([[0.2524]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  61 | Loss: 0.06297286599874496\n",
      "pred: tensor([[0.5272, 0.4689]]) tensor([[0.2523]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  62 | Loss: 0.06292684376239777\n",
      "pred: tensor([[0.5258, 0.4704]]) tensor([[0.2522]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  63 | Loss: 0.06288526952266693\n",
      "pred: tensor([[0.5245, 0.4719]]) tensor([[0.2521]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  64 | Loss: 0.06284777075052261\n",
      "pred: tensor([[0.5232, 0.4732]]) tensor([[0.2521]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  65 | Loss: 0.06281392276287079\n",
      "pred: tensor([[0.5220, 0.4746]]) tensor([[0.2520]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  66 | Loss: 0.0627833679318428\n",
      "pred: tensor([[0.5209, 0.4758]]) tensor([[0.2519]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  67 | Loss: 0.0627557709813118\n",
      "pred: tensor([[0.5198, 0.4770]]) tensor([[0.2519]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  68 | Loss: 0.06273088604211807\n",
      "pred: tensor([[0.5188, 0.4781]]) tensor([[0.2518]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  69 | Loss: 0.06270840764045715\n",
      "pred: tensor([[0.5178, 0.4792]]) tensor([[0.2517]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  70 | Loss: 0.06268813461065292\n",
      "pred: tensor([[0.5169, 0.4802]]) tensor([[0.2517]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  71 | Loss: 0.06266982853412628\n",
      "pred: tensor([[0.5161, 0.4812]]) tensor([[0.2516]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  72 | Loss: 0.0626533180475235\n",
      "pred: tensor([[0.5152, 0.4821]]) tensor([[0.2516]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  73 | Loss: 0.06263839453458786\n",
      "pred: tensor([[0.5145, 0.4830]]) tensor([[0.2515]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  74 | Loss: 0.06262492388486862\n",
      "pred: tensor([[0.5137, 0.4838]]) tensor([[0.2515]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  75 | Loss: 0.06261277198791504\n",
      "pred: tensor([[0.5130, 0.4846]]) tensor([[0.2514]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  76 | Loss: 0.06260180473327637\n",
      "pred: tensor([[0.5123, 0.4853]]) tensor([[0.2514]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  77 | Loss: 0.06259189546108246\n",
      "pred: tensor([[0.5117, 0.4860]]) tensor([[0.2513]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  78 | Loss: 0.06258296966552734\n",
      "pred: tensor([[0.5111, 0.4867]]) tensor([[0.2513]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  79 | Loss: 0.06257489323616028\n",
      "pred: tensor([[0.5105, 0.4874]]) tensor([[0.2512]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  80 | Loss: 0.06256762146949768\n",
      "pred: tensor([[0.5100, 0.4880]]) tensor([[0.2512]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  81 | Loss: 0.06256103515625\n",
      "pred: tensor([[0.5095, 0.4886]]) tensor([[0.2511]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  82 | Loss: 0.06255510449409485\n",
      "pred: tensor([[0.5090, 0.4891]]) tensor([[0.2511]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  83 | Loss: 0.06254974752664566\n",
      "pred: tensor([[0.5085, 0.4896]]) tensor([[0.2511]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  84 | Loss: 0.06254491209983826\n",
      "pred: tensor([[0.5081, 0.4902]]) tensor([[0.2510]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  85 | Loss: 0.06254053860902786\n",
      "pred: tensor([[0.5077, 0.4906]]) tensor([[0.2510]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  86 | Loss: 0.06253661215305328\n",
      "pred: tensor([[0.5073, 0.4911]]) tensor([[0.2510]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  87 | Loss: 0.06253305822610855\n",
      "pred: tensor([[0.5069, 0.4915]]) tensor([[0.2509]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  88 | Loss: 0.06252983212471008\n",
      "pred: tensor([[0.5065, 0.4919]]) tensor([[0.2509]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  89 | Loss: 0.06252694875001907\n",
      "pred: tensor([[0.5062, 0.4923]]) tensor([[0.2509]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  90 | Loss: 0.06252431869506836\n",
      "pred: tensor([[0.5059, 0.4927]]) tensor([[0.2508]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  91 | Loss: 0.06252195686101913\n",
      "pred: tensor([[0.5056, 0.4930]]) tensor([[0.2508]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  92 | Loss: 0.06251982599496841\n",
      "pred: tensor([[0.5053, 0.4934]]) tensor([[0.2508]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  93 | Loss: 0.06251790374517441\n",
      "pred: tensor([[0.5050, 0.4937]]) tensor([[0.2508]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  94 | Loss: 0.06251618266105652\n",
      "pred: tensor([[0.5047, 0.4940]]) tensor([[0.2507]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  95 | Loss: 0.06251458823680878\n",
      "pred: tensor([[0.5045, 0.4943]]) tensor([[0.2507]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  96 | Loss: 0.06251318007707596\n",
      "pred: tensor([[0.5043, 0.4946]]) tensor([[0.2507]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  97 | Loss: 0.06251190602779388\n",
      "pred: tensor([[0.5040, 0.4948]]) tensor([[0.2507]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  98 | Loss: 0.06251074373722076\n",
      "pred: tensor([[0.5038, 0.4951]]) tensor([[0.2506]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  99 | Loss: 0.06250971555709839\n",
      "tensor([[0.5038, 0.4951]]) tensor([[0.2506]])\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "lr = 0.1\n",
    "\n",
    "w, b = train(n_epochs, lr, w, b, x, y)\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2Ny-YkAaNh8"
   },
   "source": [
    "잘 수렴하는 것을 확인하였습니다. 마지막으로 OR data에 대한 $w, b$의 예측 결과와 label을 비교해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1723361279283,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "IggGP969Bh-w",
    "outputId": "c9a5ccb0-5fdc-4f86-ed30-157f56f97d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[0.5038, 0.4951]]) tensor([[0.2506]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "tensor([[0.2506, 0.7457, 0.7545, 1.2495]])\n",
      "tensor([0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(pred(w, b, x))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8gKvx2naWDP"
   },
   "source": [
    "아래 값으로 수렴하는 것을 볼 수 있음\n",
    "\n",
    "tensor([[0.2500, 0.7500, 0.7500, 1.2500]])\n",
    "tensor([0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 결과를 볼 수 있다시피 우리의 linear regression model은 0과 1에 해당하는 data를 잘 구분하는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMXZLfd3DC50"
   },
   "source": [
    "# XOR Problem\n",
    "\n",
    "이번에는 XOR를 학습해보겠습니다. XOR은 OR과 똑같은 입력을 받는 문제로, 두 개의 0 또는 1의 정수가 들어왔을 때 두 정수가 다르면 1, 아니면 0을 출력해야 합니다.\n",
    "먼저 data를 만들어보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1723361279283,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "JtFGsqNXCjtM",
    "outputId": "7183941e-8298-4f2d-f443-9c20f39aec11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# x = torch.tensor([\n",
    "#     [0., 0.],\n",
    "#     [0., 1.],\n",
    "#     [1., 0.],\n",
    "#     [1., 1.]\n",
    "# ])\n",
    "# y = torch.tensor([0, 1, 1, 0])\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYRtKaviaedO"
   },
   "source": [
    "보시다시피 shape이나 생성 과정은 OR과 똑같습니다. 다른 것은 $y$에서의 labeling입니다. OR과 다르게 $x = (1, 1)$에 대해서는 0을 labeling했습니다.\n",
    "이러한 사소한 차이에 대해서도 linear regression model이 잘 학습할 수 있을지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "여러번 돌려보면서 w,b 가  수렴하는 것을 볼 수 있음\n",
    "\n",
    "그런데 그것과 별개로 loss가 0.25로 수렴하는 것도 확인 할 수 있는데\n",
    "왜 그렇게 되는지 의문임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1723361279283,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "iw5UUqKdDG98",
    "outputId": "b37eb7e7-ff7f-4887-e432-c5f597179f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[0.5036, 0.4953]]) tensor([[0.2506]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   0 | Loss: 0.06250877678394318\n",
      "pred: tensor([[0.5034, 0.4955]]) tensor([[0.2506]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   1 | Loss: 0.06250791996717453\n",
      "pred: tensor([[0.5032, 0.4958]]) tensor([[0.2506]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   2 | Loss: 0.06250714510679245\n",
      "pred: tensor([[0.5031, 0.4960]]) tensor([[0.2506]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   3 | Loss: 0.06250645965337753\n",
      "pred: tensor([[0.5029, 0.4962]]) tensor([[0.2505]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   4 | Loss: 0.0625058189034462\n",
      "pred: tensor([[0.5028, 0.4963]]) tensor([[0.2505]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   5 | Loss: 0.06250526010990143\n",
      "pred: tensor([[0.5026, 0.4965]]) tensor([[0.2505]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   6 | Loss: 0.06250474601984024\n",
      "pred: tensor([[0.5025, 0.4967]]) tensor([[0.2505]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   7 | Loss: 0.06250429898500443\n",
      "pred: tensor([[0.5023, 0.4968]]) tensor([[0.2505]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   8 | Loss: 0.0625038743019104\n",
      "pred: tensor([[0.5022, 0.4970]]) tensor([[0.2505]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch   9 | Loss: 0.06250349432229996\n",
      "pred: tensor([[0.5021, 0.4971]]) tensor([[0.2504]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  10 | Loss: 0.06250316649675369\n",
      "pred: tensor([[0.5020, 0.4973]]) tensor([[0.2504]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  11 | Loss: 0.06250285357236862\n",
      "pred: tensor([[0.5019, 0.4974]]) tensor([[0.2504]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  12 | Loss: 0.06250257790088654\n",
      "pred: tensor([[0.5018, 0.4975]]) tensor([[0.2504]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  13 | Loss: 0.06250232458114624\n",
      "pred: tensor([[0.5017, 0.4976]]) tensor([[0.2504]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  14 | Loss: 0.06250210106372833\n",
      "pred: tensor([[0.5016, 0.4978]]) tensor([[0.2504]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  15 | Loss: 0.06250189989805222\n",
      "pred: tensor([[0.5015, 0.4979]]) tensor([[0.2504]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  16 | Loss: 0.0625017061829567\n",
      "pred: tensor([[0.5014, 0.4980]]) tensor([[0.2503]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  17 | Loss: 0.06250155717134476\n",
      "pred: tensor([[0.5014, 0.4981]]) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2503]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  18 | Loss: 0.06250140070915222\n",
      "pred: tensor([[0.5013, 0.4982]]) tensor([[0.2503]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  19 | Loss: 0.06250126659870148\n",
      "pred: tensor([[0.5012, 0.4982]]) tensor([[0.2503]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  20 | Loss: 0.06250114738941193\n",
      "pred: tensor([[0.5012, 0.4983]]) tensor([[0.2503]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  21 | Loss: 0.06250104308128357\n",
      "pred: tensor([[0.5011, 0.4984]]) tensor([[0.2503]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  22 | Loss: 0.06250093877315521\n",
      "pred: tensor([[0.5010, 0.4985]]) tensor([[0.2503]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  23 | Loss: 0.06250083446502686\n",
      "pred: tensor([[0.5010, 0.4986]]) tensor([[0.2503]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  24 | Loss: 0.06250076740980148\n",
      "pred: tensor([[0.5009, 0.4986]]) tensor([[0.2503]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  25 | Loss: 0.06250069290399551\n",
      "pred: tensor([[0.5009, 0.4987]]) tensor([[0.2503]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  26 | Loss: 0.06250061839818954\n",
      "pred: tensor([[0.5008, 0.4988]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  27 | Loss: 0.06250055879354477\n",
      "pred: tensor([[0.5008, 0.4988]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  28 | Loss: 0.06250050663948059\n",
      "pred: tensor([[0.5007, 0.4989]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  29 | Loss: 0.06250045448541641\n",
      "pred: tensor([[0.5007, 0.4989]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  30 | Loss: 0.06250041723251343\n",
      "pred: tensor([[0.5007, 0.4990]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  31 | Loss: 0.06250037997961044\n",
      "pred: tensor([[0.5006, 0.4990]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  32 | Loss: 0.06250034272670746\n",
      "pred: tensor([[0.5006, 0.4991]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  33 | Loss: 0.06250030547380447\n",
      "pred: tensor([[0.5006, 0.4991]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  34 | Loss: 0.06250027567148209\n",
      "pred: tensor([[0.5005, 0.4992]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  35 | Loss: 0.0625002384185791\n",
      "pred: tensor([[0.5005, 0.4992]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  36 | Loss: 0.0625002309679985\n",
      "pred: tensor([[0.5005, 0.4992]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  37 | Loss: 0.06250021606683731\n",
      "pred: tensor([[0.5004, 0.4993]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  38 | Loss: 0.06250020116567612\n",
      "pred: tensor([[0.5004, 0.4993]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  39 | Loss: 0.06250017881393433\n",
      "pred: tensor([[0.5004, 0.4993]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  40 | Loss: 0.06250015646219254\n",
      "pred: tensor([[0.5004, 0.4994]]) tensor([[0.2502]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  41 | Loss: 0.06250014901161194\n",
      "pred: tensor([[0.5004, 0.4994]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  42 | Loss: 0.06250011175870895\n",
      "pred: tensor([[0.5003, 0.4994]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  43 | Loss: 0.06250011175870895\n",
      "pred: tensor([[0.5003, 0.4994]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  44 | Loss: 0.06250010430812836\n",
      "pred: tensor([[0.5003, 0.4995]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  45 | Loss: 0.06250009685754776\n",
      "pred: tensor([[0.5003, 0.4995]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  46 | Loss: 0.06250008940696716\n",
      "pred: tensor([[0.5003, 0.4995]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  47 | Loss: 0.06250007450580597\n",
      "pred: tensor([[0.5003, 0.4995]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  48 | Loss: 0.06250007450580597\n",
      "pred: tensor([[0.5002, 0.4996]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  49 | Loss: 0.06250005960464478\n",
      "pred: tensor([[0.5002, 0.4996]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  50 | Loss: 0.06250005960464478\n",
      "pred: tensor([[0.5002, 0.4996]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  51 | Loss: 0.06250005215406418\n",
      "pred: tensor([[0.5002, 0.4996]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  52 | Loss: 0.06250003725290298\n",
      "pred: tensor([[0.5002, 0.4996]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  53 | Loss: 0.06250003725290298\n",
      "pred: tensor([[0.5002, 0.4997]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  54 | Loss: 0.06250005215406418\n",
      "pred: tensor([[0.5002, 0.4997]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  55 | Loss: 0.06250002980232239\n",
      "pred: tensor([[0.5002, 0.4997]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  56 | Loss: 0.06250002980232239\n",
      "pred: tensor([[0.5001, 0.4997]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  57 | Loss: 0.06250002235174179\n",
      "pred: tensor([[0.5001, 0.4997]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  58 | Loss: 0.06250002235174179\n",
      "pred: tensor([[0.5001, 0.4997]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  59 | Loss: 0.06250002980232239\n",
      "pred: tensor([[0.5001, 0.4997]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  60 | Loss: 0.0625000149011612\n",
      "pred: tensor([[0.5001, 0.4998]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  61 | Loss: 0.06250002235174179\n",
      "pred: tensor([[0.5001, 0.4998]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  62 | Loss: 0.0625000074505806\n",
      "pred: tensor([[0.5001, 0.4998]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  63 | Loss: 0.0625000149011612\n",
      "pred: tensor([[0.5001, 0.4998]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  64 | Loss: 0.06250002235174179\n",
      "pred: tensor([[0.5001, 0.4998]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  65 | Loss: 0.06250002235174179\n",
      "pred: tensor([[0.5001, 0.4998]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  66 | Loss: 0.0625000149011612\n",
      "pred: tensor([[0.5001, 0.4998]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  67 | Loss: 0.06250002235174179\n",
      "pred: tensor([[0.5001, 0.4998]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  68 | Loss: 0.0625\n",
      "pred: tensor([[0.5001, 0.4998]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  69 | Loss: 0.0625\n",
      "pred: tensor([[0.5001, 0.4998]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  70 | Loss: 0.0624999962747097\n",
      "pred: tensor([[0.5001, 0.4998]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  71 | Loss: 0.0625\n",
      "pred: tensor([[0.5001, 0.4999]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  72 | Loss: 0.0625\n",
      "pred: tensor([[0.5001, 0.4999]]) tensor([[0.2501]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  73 | Loss: 0.0625\n",
      "pred: tensor([[0.5001, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  74 | Loss: 0.0625000149011612\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  75 | Loss: 0.0625\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  76 | Loss: 0.0625000074505806\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  77 | Loss: 0.0624999925494194\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  78 | Loss: 0.0625000149011612\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  79 | Loss: 0.0625\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  80 | Loss: 0.0625\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  81 | Loss: 0.0625\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  82 | Loss: 0.0624999925494194\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  83 | Loss: 0.0625\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  84 | Loss: 0.0625000149011612\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  85 | Loss: 0.0624999962747097\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  86 | Loss: 0.0625\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  87 | Loss: 0.0625\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  88 | Loss: 0.0624999925494194\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  89 | Loss: 0.0624999962747097\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  90 | Loss: 0.0625\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  91 | Loss: 0.0624999925494194\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  92 | Loss: 0.0624999962747097\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  93 | Loss: 0.0625\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  94 | Loss: 0.0625000074505806\n",
      "pred: tensor([[0.5000, 0.4999]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  95 | Loss: 0.0625000074505806\n",
      "pred: tensor([[0.5000, 0.5000]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  96 | Loss: 0.0624999962747097\n",
      "pred: tensor([[0.5000, 0.5000]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  97 | Loss: 0.0624999962747097\n",
      "pred: tensor([[0.5000, 0.5000]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  98 | Loss: 0.0625\n",
      "pred: tensor([[0.5000, 0.5000]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "Epoch  99 | Loss: 0.0625\n",
      "tensor([[0.5000, 0.5000]]) tensor([[0.2500]])\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "lr = 0.1\n",
    "\n",
    "w, b = train(n_epochs, lr, w, b, x, y)\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8sMLaJ9a770"
   },
   "source": [
    "이전과는 다르게 loss가 1.0보다 작아지지 않는 것을 알 수 있습니다. 실제 예측 결과를 살펴보면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1723361279283,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "L81iXxgHDIq2",
    "outputId": "1fc0cef5-f24d-45e7-bc0a-fc91c82762b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[0.5000, 0.5000]]) tensor([[0.2500]]) tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "tensor([[0.2500, 0.7500, 0.7500, 1.2500]])\n",
      "tensor([0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(pred(w, b, x))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuqkwJ2NbB7S"
   },
   "source": [
    "보시다시피 0과 1에 해당하는 data들을 잘 구분하지 못하는 모습니다. Linear regression model은 XOR을 잘 처리하지 못하는 것을 우리는 이번 실습을 통해 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1723361279283,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "2zAy7YgFDMgx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN2/ufUFmLdn0BAFVwEnpdC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
